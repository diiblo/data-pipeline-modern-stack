{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad43bee7-b094-44dd-a09c-cbb04bfb4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d’environnement (.env)\n",
    "load_dotenv()\n",
    "\n",
    "# Récupérer les identifiants depuis .env\n",
    "minio_endpoint = os.getenv(\"MINIO_ENDPOINT\")\n",
    "minio_access_key = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "minio_secret_key = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "bucket = os.getenv(\"MINIO_BUCKET\")\n",
    "\n",
    "# Initialisation de la SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TransformEcommerceData\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{minio_endpoint}\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", minio_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", minio_secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a5e4bc-86db-4c17-b402-49d34df572d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: float (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|565541   |20972    |PINK CREAM FELT CRAFT TRINKET BOX |3       |9/5/2011 12:00|1.25     |14159     |United Kingdom|\n",
      "|565541   |22620    |4 TRADITIONAL SPINNING TOPS       |2       |9/5/2011 12:00|1.45     |14159     |United Kingdom|\n",
      "|565541   |22621    |TRADITIONAL KNITTING NANCY        |2       |9/5/2011 12:00|1.65     |14159     |United Kingdom|\n",
      "|565541   |21891    |TRADITIONAL WOODEN SKIPPING ROPE  |2       |9/5/2011 12:00|1.45     |14159     |United Kingdom|\n",
      "|565541   |21892    |TRADITIONAL WOODEN CATCH CUP GAME |2       |9/5/2011 12:00|1.25     |14159     |United Kingdom|\n",
      "+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Lecture brute\n",
    "raw_df = spark.read \\\n",
    "    .option(\"encoding\", \"ISO-8859-1\") \\\n",
    "    .text(f\"s3a://{bucket}/raw/ecommerce/ecommerce.csv\")\n",
    "\n",
    "# 2️⃣ Supprimer les lignes parasites (SET avec espaces, BOM, etc.)\n",
    "filtered_df = raw_df.filter(~col(\"value\").rlike(r\"(?i)^.*\\bSET\\b.*\")) \\\n",
    "                    .filter(col(\"value\").isNotNull()) \\\n",
    "                    .filter(~col(\"value\").rlike(r\"^\\s*$\"))\n",
    "\n",
    "# 3️⃣ Split manuel sur les virgules\n",
    "split_df = filtered_df.withColumn(\"splitted\", split(col(\"value\"), \",\"))\n",
    "\n",
    "# 4️⃣ Créer les vraies colonnes (on repart uniquement de 'split_df')\n",
    "df = split_df.select(\n",
    "    col(\"splitted\")[0].alias(\"InvoiceNo\"),\n",
    "    col(\"splitted\")[1].alias(\"StockCode\"),\n",
    "    col(\"splitted\")[2].alias(\"Description\"),\n",
    "    col(\"splitted\")[3].cast(\"int\").alias(\"Quantity\"),\n",
    "    col(\"splitted\")[4].alias(\"InvoiceDate\"),\n",
    "    col(\"splitted\")[5].cast(\"float\").alias(\"UnitPrice\"),\n",
    "    col(\"splitted\")[6].alias(\"CustomerID\"),\n",
    "    col(\"splitted\")[7].alias(\"Country\")\n",
    ")\n",
    "\n",
    "# 5️⃣ Aperçu\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
