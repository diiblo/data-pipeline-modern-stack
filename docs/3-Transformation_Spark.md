## ğŸš€ Ã‰tape 3 â€“ Lecture du fichier avec Spark

---

### ğŸ¯ Objectif pÃ©dagogique

Tu vas :
- Lire un fichier distant dans MinIO (S3) depuis Spark
- Comprendre la configuration S3A dans Spark
- Utiliser un `DataFrame` Spark pour inspecter et transformer les donnÃ©es

---

## ğŸ§  Ce que tu dois savoir avant de coder

### ğŸ”¹ Comment Spark accÃ¨de Ã  MinIO :
Spark utilise un **connecteur S3A** (dÃ©jÃ  dans ton image via `hadoop-aws`)  
Mais il a besoin de :
- `endpoint` MinIO
- Access/secret keys
- Type dâ€™accÃ¨s (`path-style` pour MinIO)

---

## âœ… Code Spark complet pour lire ton fichier

ğŸ“ Place ce code dans un **Notebook** (`notebooks/lecture_ecommerce.ipynb`)  
ou dans un script `spark_jobs/read_raw_ecommerce.py`

```python
from pyspark.sql import SparkSession
from dotenv import load_dotenv
import os

# Charger les variables dâ€™environnement (.env)
load_dotenv()

# RÃ©cupÃ©rer les identifiants depuis .env
minio_endpoint = os.getenv("MINIO_ENDPOINT", "minio:9000")
minio_access_key = os.getenv("MINIO_ACCESS_KEY", "admin")
minio_secret_key = os.getenv("MINIO_SECRET_KEY", "admin123")
bucket = os.getenv("MINIO_BUCKET", "datalake")

# Initialisation de la SparkSession
spark = SparkSession.builder \
    .appName("ReadEcommerceRawFromMinIO") \
    .master("spark://spark-master:7077") \
    .config("spark.hadoop.fs.s3a.endpoint", f"http://{minio_endpoint}") \
    .config("spark.hadoop.fs.s3a.access.key", minio_access_key) \
    .config("spark.hadoop.fs.s3a.secret.key", minio_secret_key) \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .getOrCreate()

# ğŸ“„ Lecture du fichier CSV (dans le bucket 'datalake')
df = spark.read \
    .option("header", True) \
    .option("inferSchema", True) \
    .csv("s3a://datalake/raw/ecommerce/ecommerce.csv")

# ğŸ§ª AperÃ§u
df.printSchema()
df.show(5, truncate=False)
```

---

## âœ… Ce que tu dois voir s'afficher :

- Le **schÃ©ma** infÃ©rÃ© par Spark (types, colonnes comme `InvoiceNo`, `Quantity`, `UnitPrice`, etc.)
- Les **5 premiÃ¨res lignes**

---

## ğŸ§  Ã€ comprendre ici :

| Ã‰lÃ©ment Spark                            | Ce que Ã§a fait                                |
|-----------------------------------------|-----------------------------------------------|
| `s3a://...`                              | AccÃ¨s Ã  un fichier via S3 API                 |
| `.option("inferSchema", True)`           | Laisse Spark deviner les types des colonnes   |
| `.option("header", True)`                | Utilise la premiÃ¨re ligne comme noms de colonnes |
| `printSchema()`                          | Affiche les types infÃ©rÃ©s par Spark           |
| `show()`                                 | Affiche un aperÃ§u des donnÃ©es                 |